{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example script to generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text():\n",
    "    path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "    with open(path) as f:\n",
    "        text = f.read().lower()\n",
    "    print('corpus length:', len(text))\n",
    "    return text\n",
    "\n",
    "def build_dict(text):\n",
    "    chars = sorted(list(set(text)))\n",
    "    print('total chars:', len(chars))\n",
    "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "    return char_indices, indices_char, len(chars)\n",
    "\n",
    "def vectorize(text, char_indices, indices_char, dict_size, maxlen = 40, step = 3):\n",
    "    ''' cut the text in semi-redundant sequences of maxlen characters'''\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - maxlen, step):\n",
    "        sentences.append(text[i: i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "    print('nb sequences:', len(sentences))\n",
    "\n",
    "    print('Vectorization...')\n",
    "    x = np.zeros((len(sentences), maxlen, dict_size), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), dict_size), dtype=np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(units, maxlen, dict_size):\n",
    "    ''' build the model: a single LSTM '''\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, input_shape=(maxlen, dict_size)))\n",
    "    model.add(Dense(dict_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    ''' helper function to sample an index from a probability array '''\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_samples(model, text, maxlen, char_indices, indices_char, dict_size, sample_size = 40):\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            x_pred = np.zeros((1, maxlen, dict_size))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_sample(model, x, y, iterations, epochs, maxlen, char_indices, indices_char, dict_size, sample_size):\n",
    "    ''' train the model, output generated text after each iteration '''\n",
    "    for iteration in range(1, iterations):\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "        model.fit(x, y, batch_size=128, epochs=epochs, verbose = 1)\n",
    "\n",
    "        if iteration % int(iterations / 10) == 0:\n",
    "            generate_samples(model, text, maxlen, char_indices, indices_char, dict_size, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen, step = 2, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "text = get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 42\n"
     ]
    }
   ],
   "source": [
    "char_indices, indices_char, dict_size = build_dict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 4998\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "x, y = vectorize(text, char_indices, indices_char, dict_size, maxlen, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4998, 2, 42), (4998, 42))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 32)                9600      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 42)                1386      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 42)                0         \n",
      "=================================================================\n",
      "Total params: 10,986\n",
      "Trainable params: 10,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(32, maxlen, dict_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4998/4998 [==============================] - 0s - loss: 3.0032     \n",
      "Epoch 2/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.6058     \n",
      "Epoch 3/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.4483     \n",
      "Epoch 4/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.3759     \n",
      "Epoch 5/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.3170     \n",
      "Epoch 6/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.2775     \n",
      "Epoch 7/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.2359     \n",
      "Epoch 8/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.2068     \n",
      "Epoch 9/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.1741     \n",
      "Epoch 10/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.1509     \n",
      "Epoch 11/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.1214     \n",
      "Epoch 12/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.0991     \n",
      "Epoch 13/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.0773     \n",
      "Epoch 14/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.0579     \n",
      "Epoch 15/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.0410     \n",
      "Epoch 16/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.0225     \n",
      "Epoch 17/50\n",
      "4998/4998 [==============================] - 0s - loss: 2.0055     \n",
      "Epoch 18/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.9910     \n",
      "Epoch 19/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.9772     \n",
      "Epoch 20/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.9630     \n",
      "Epoch 21/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.9486     \n",
      "Epoch 22/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.9376     \n",
      "Epoch 23/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.9251     \n",
      "Epoch 24/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.9126     \n",
      "Epoch 25/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.9037     \n",
      "Epoch 26/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8948     \n",
      "Epoch 27/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8872     \n",
      "Epoch 28/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8751     \n",
      "Epoch 29/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8683     \n",
      "Epoch 30/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8580     \n",
      "Epoch 31/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8523     \n",
      "Epoch 32/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8458     \n",
      "Epoch 33/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8370     \n",
      "Epoch 34/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8345     \n",
      "Epoch 35/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8264     \n",
      "Epoch 36/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8200     \n",
      "Epoch 37/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8173     \n",
      "Epoch 38/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8137     \n",
      "Epoch 39/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8087     \n",
      "Epoch 40/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.8066     \n",
      "Epoch 41/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.7965     \n",
      "Epoch 42/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.7961     \n",
      "Epoch 43/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.7889     \n",
      "Epoch 44/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.7881     \n",
      "Epoch 45/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.7839     \n",
      "Epoch 46/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.7822     \n",
      "Epoch 47/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.7791     \n",
      "Epoch 48/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.7751     \n",
      "Epoch 49/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.7715     \n",
      "Epoch 50/50\n",
      "4998/4998 [==============================] - 0s - loss: 1.7694     \n"
     ]
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=128, epochs=50, verbose = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ug\"\n",
      "uggle the and the been of struthe stion of st the be\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ug\"\n",
      "uggle the and pers the sperseady phy ity have per th\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ug\"\n",
      "uggll pues and--all posocrow! bef): ders\n",
      "anialateare\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ug\"\n",
      "uggmionibled form thave noluscityrutens,\n",
      "agasoutends\n"
     ]
    }
   ],
   "source": [
    "genearte_samples(model, text, maxlen, char_indices, indices_char, dict_size, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7368     \n",
      "Epoch 2/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7380     \n",
      "Epoch 3/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7320     \n",
      "Epoch 4/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7376     \n",
      "Epoch 5/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7295     \n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" s\"\n",
      " stiment the the purous the the the the prearithe an\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" s\"\n",
      " strut perthe be that the phistand perto itherthenti\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" s\"\n",
      " sperto tow whilen of whumatialless, te\n",
      "prout grtain\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" s\"\n",
      " scans--ined noresia,strutherly mounicedich, onstre-\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7296     \n",
      "Epoch 2/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7287     \n",
      "Epoch 3/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7294     \n",
      "Epoch 4/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7245     \n",
      "Epoch 5/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7267     \n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"f \"\n",
      "f the and the spirstion and the stion of yet the and\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"f \"\n",
      "f was as thism, that pat the all to ing and the of s\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"f \"\n",
      "f it th an for a phictudems\n",
      "anit onstruthierspirstiq\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"f \"\n",
      "f se, pattrupprespophis se go\n",
      "wichrill--nably grtien\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7237     - ETA: 0s - loss: \n",
      "Epoch 2/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7237     \n",
      "Epoch 3/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7223     \n",
      "Epoch 4/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7201     \n",
      "Epoch 5/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7198     \n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"on\"\n",
      "on they and the beenters and they and the of to to t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"on\"\n",
      "on us ands haver the to to the the hat they hatiloso\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"on\"\n",
      "on its by plat truggle gerstit in to speen us of who\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"on\"\n",
      "onspiriquesselgfally\n",
      "ands, st\n",
      "ity in yet grilonsin t\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7184     - ETA: 0s - loss: 1.\n",
      "Epoch 2/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7146     \n",
      "Epoch 3/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7169     \n",
      "Epoch 4/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7128     \n",
      "Epoch 5/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7122     \n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" l\"\n",
      " lat the and to the and the spers and to the hat the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" l\"\n",
      " libeension thems of tion all to tion of to the the \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" l\"\n",
      " lost listiria thophy, breas if ditilums a ple quonc\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" l\"\n",
      " le we pre its of for\n",
      "\n",
      "nifich evers\n",
      "of whe ea, wit\n",
      "a\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7118     \n",
      "Epoch 2/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7125     \n",
      "Epoch 3/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7101     \n",
      "Epoch 4/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7125     \n",
      "Epoch 5/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7085     \n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"at\"\n",
      "at the be and the pery and the selve dous and the an\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"at\"\n",
      "at in and be phis of the be dersery ing in of suit a\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"at\"\n",
      "aterve\n",
      "s\n",
      "abowly caps truppeany a ater se ailly  is e\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"at\"\n",
      "at seenser, thery thits--not magmade mow! as not dri\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7031     \n",
      "Epoch 2/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7080     \n",
      "Epoch 3/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7049     \n",
      "Epoch 4/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7067     \n",
      "Epoch 5/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7062     \n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ug\"\n",
      "uggle gror the press, the press, the press, a dersti\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ug\"\n",
      "uggle st in at a and therst lat ther the it a lat pr\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ug\"\n",
      "uggleente\"--wer all truthilosopeast unight, arlut li\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ug\"\n",
      "ugh? wilostalne fre beems correve--whis werits thent\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7048     \n",
      "Epoch 2/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7023     \n",
      "Epoch 3/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7014     \n",
      "Epoch 4/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.6977     \n",
      "Epoch 5/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7016     \n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e\n",
      "\"\n",
      "e\n",
      "prestion such and the grat the be be and the be be\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e\n",
      "\"\n",
      "e\n",
      "as and as ast the ser und st in spere of so then o\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e\n",
      "\"\n",
      "e\n",
      "hist hagail, good all a eurst amet haverpatimmay! \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e\n",
      "\"\n",
      "e\n",
      "(suit gold sids, we by be supts bef): dousm andect\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.6956     \n",
      "Epoch 2/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7002     \n",
      "Epoch 3/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.7012     \n",
      "Epoch 4/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.6972     \n",
      "Epoch 5/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.6994     \n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"\n",
      "a\"\n",
      "\n",
      "and the the stion of the and the be and the be the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"\n",
      "a\"\n",
      "\n",
      "ation good hat be hat hat the st therto stion sperh\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"\n",
      "a\"\n",
      "\n",
      "ably alrout not the senpiribe the factransempophice\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"\n",
      "a\"\n",
      "\n",
      "aceps thous he bread deffice, ts stimsy scian--fori\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.6984     \n",
      "Epoch 2/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.6981     \n",
      "Epoch 3/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.6951     \n",
      "Epoch 4/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.6967     \n",
      "Epoch 5/5\n",
      "4998/4998 [==============================] - 0s - loss: 1.6943     \n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" a\"\n",
      " a such as a con of the of the a con of the such as \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" a\"\n",
      " and in on of the the of there to\n",
      "unds hat sere hent\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" a\"\n",
      " an of tionay famen stit berhaimptes--to me, aus, as\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" a\"\n",
      " an\n",
      "fureemomight sor\n",
      "beful-swer of haverto\n",
      "knorerrow\n"
     ]
    }
   ],
   "source": [
    "train_and_sample(model, x, y, 10, 5, maxlen, char_indices, indices_char, dict_size, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
